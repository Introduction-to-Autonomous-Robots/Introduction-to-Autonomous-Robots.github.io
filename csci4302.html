---
permalink: csci4302.html
title: "CSCI 4302 -- Advanced Robotics"
description: "Manipulation"
type: csci4302
---

# Description

The overarching learning goal of this class is to create an appreciation for the tight interplay between mechanism, sensor, and control in the design of intelligent systems. This includes (1) formally describing the forward and inverse kinematics of a mechanism, (2) understanding the sources of uncertainty in sensing and actuation as well as to describe them mathematically, (3) how to discretize the robot’s state and reason about it algorithmically, and (4) experiencing 1-3 in physic-based simulation or on a real robotic platform.

In Spring 2022, this class is taught as a "special topics" class CSCI4830/7000 to broadly explore the topic "Robotic Manipulation".

## Meet the Team

 * Spring 2022
   * Instructor: Nikolaus Correll

# Syllabus

Understand the specific challenges in robotic manipulation, ranging from mechanisms to sensing, perception, and control.

|&nbsp;&nbsp;&nbsp;Week&nbsp;&nbsp;&nbsp;| Content | Reading |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lab&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|
| :---: | :------- | :--- | :--- |
| 1   | Manipulation overview | [Robots getting a grip on manipulation](https://www.youtube.com/watch?v=nV5dm42ZR_c), IROS 2020 keynote | [Intro to Webots]({% post_url labs/advanced/2022-01-12-Lab_0_Introduction_to_Webots_Manipulation %}) |
| 2   | Coordination systems and frames of reference | Section 2.3-4 | [Inverse kinematics]({% post_url labs/advanced/2022-01-16-Lab_1_Inverse_Kinematics %}) |
| 3   | Forward and inverse kinematics of manipulators | Sections 3.1-3 | Inverse kinematics |
| 4   | Forces | Chapter 4 | Inverse kinematics |
| 5   | Grasping | Chapter 5 | [Grasping]({% post_url labs/advanced/2022-02-06-Lab_2_Point_Clouds %}) |
| 6   | Actuation for manipulation | Chapter 6, ["Systems, devices, components, and methods for a compact robotic gripper with palm-mounted sensing, grasping, and computing devices and components." U.S. Patent No. 11,148,295](https://patents.google.com/patent/US11148295B2/en) | Grasping |
| 7   | Sensors for manipulation | Chapter 7 | [Collision avoidance]({% post_url labs/advanced/2022-02-24-Lab_3_Collision_Avoidance.md %}) |
| 8   | Vision for manipulation | Chapter 8 | Collision avoidance |
| 9   | Features: segmentation and PCA | Chapter 9, Section B.5 | Object recognition |
| 10  | Task execution using Behavior Trees | Chapter 11 | Object recognition |
| 11  | Manipulation planning | Chapter 14 | Bin picking |
| 12  | Uncertainty | Chapter 16 | Bin picking |
| 13  | Project | Chapter E | Project |
| 14  | Project | no reading | Project |
| 15  | Project presentations | no reading | Project |

Labs are due Wednesday evening at 6pm prior to the begin of the next lab. There are no extensions. There is no collaboration on labs allowed. We will be working on labs together in class and you are welcome to discuss your approach with fellow students, but each submission needs to be your own. (Plagiarism is enforced using automated tools.) The project instead is encouraged to be a team effort.
 
## Lab 0: Introduction to Webots (Manipulation)

{% include image.html url="labs/UR5cans.png" max-width="45%" description="A UR5e robot picking up a can" %}

The goal of this lab is to understand the architecture and key data structures in Webots and how to access them from Python. You will augment a manipulating arm with a 3D camera and visualize its data stream in a Python notebook. 

## Lab 1: Inverse kinematics

The goal of this lab is to implement basic inverse kinematics that allows a Universal Robot UR5 to move from point to point following the shortest path in Cartesian and Joint space (akin to the "moveL" and "moveJ" that the real UR5 API provides). You will first implement a closed-form solution of the UR5's inverse kinematics and then implement a basic trajectory following algorithm. These commands will be demonstrated by moving the robot above a red ball placed underneath it. This will require mounting a stereo camera at the robot's end-effector and implementation of basic image processing routines.  

{% include image.html url="labs/UR5IK.png" max-width="45%" description="A UR5e robot" %}
## Lab 2: Grasping

The goal of this lab is to implement basic point cloud processing algorithms to detect and localize the cans as they come on the conveyor belt. This lab requires a working implementation of inverse kinematics, trajectory controller, and state machine from labs 0 and 1.

{% include image.html url="labs/canpcl.png" max-width="45%" description="A soda can and the conveyor belt after processing in Open3D" %}

## Lab 3: Collision avoidance

The goal of this lab is to implement a simple collision avoidance pipeline. The UR5 is positioned above a bin with known dimensions. You will first model the bin and the robot end-effector in a simple physics simulator (bullet). Here, the bin dimensions are given and you simply need to detect the bin in the 3D camera data. 

{% include image.html url="labs/cansegmentation.png" max-width="45%" description="A basket of soda cans after segmentation" %}

## Lab 4: Object recognition
The goal of this lab is to identify individual objects in dense, cluttered environments such as a bin. 
Implement a simple segmentation algorithm (DBSCAN) to identify individual balls in the environment and use principal component analysis to identify possible grasp poses. 

## Lab 5: Bin picking
Use your object recognition, collision avoidance, and inverse kinematic code to implement a Behavior Tree for bin picking. 

## Project

You have developed a complete solution for bin picking, starting with object segmentation, grasp generation, collision avoidance, and dealing with uncertainty. Do you have an idea on how to improve one of these components? Did you come across an interesting method that you wish to test? Your project will require a clear hyptothesis and an experimental design in Webots. The final deliverable is a paper (4-6 pages, IEEE double column format) that describes your experimental setup and your findings.  

## Grading

Lab (50%), Final Project (35%), Attendance/Participation (15%)


## Textbook

"Introduction to Autonomous Robotics” by Nikolaus Correll [[LINK]](https://github.com/Introduction-to-Autonomous-Robots/Introduction-to-Autonomous-Robots)


## Notes on Webots

* Webots is available as binary for Windows, Linux and Mac from [www.cyberbotics.com](http://www.cyberbotics.com). You will need to install a python interpreter and setup Webots to use it.

* Follow the instructions in the [Webots Reference Manual](https://cyberbotics.com/doc/guide/running-extern-robot-controllers) to understand how to use external controllers in order to use Jupyter lab, ipython or other tools with better debugging capabilities. 
